{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df7c92e-49ac-4e91-8439-08d001b5a6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This notebook is used to find the white card in the live bee images and rotate and crop to it.\n",
    "It does this by:\n",
    " 1. Doing canny edge detection on the image to find the edges of the card\n",
    " 2. Rotating the card so the edges are now vertical\n",
    " 3. Cropping the image to the card\n",
    " 4. Saving the new image with just the card\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58f2218c-ec02-46d2-9406-e1d5c4096054",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import cv2\n",
    "import time\n",
    "import json\n",
    "import shutil\n",
    "import easyocr\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "\n",
    "\n",
    "from copy import deepcopy\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from skimage.feature import match_template\n",
    "from scipy import ndimage\n",
    "from skimage.io import imread\n",
    "from scipy.signal import fftconvolve\n",
    "from skimage.feature import peak_local_max\n",
    "\n",
    "from skimage import feature\n",
    "\n",
    "from skimage.transform import hough_line, hough_line_peaks\n",
    "from skimage.feature import canny\n",
    "\n",
    "from skimage.exposure import match_histograms\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd189ff8-a4ed-4984-a47c-83f7a20753aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename some bee images (Can see the number in the image)\n",
    "renames = {'../WWBEE24_images/Round01/Hive03/2024_06_20/IMG_0016.JPG':'../WWBEE24_images/Round01/Hive03/2024_06_20/h03b16.JPG',\n",
    "          '../WWBEE24_images/Round02/hive15/2024_06_21/IMG_0036.JPG':'../WWBEE24_images/Round02/hive15/2024_06_21/h15b18.JPG'}\n",
    "for k,v in renames.items():\n",
    "    if os.path.exists(k):\n",
    "        shutil.move(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3203ead-59ba-4550-93d5-edf0687305d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_horizontal_edge_intersection_points(image, line):\n",
    "    angle, dist = line\n",
    "    # get where line crosses top edge\n",
    "    top = int(dist/np.cos(-angle))\n",
    "\n",
    "\n",
    "    # get where line crosses bottom edge\n",
    "    bott = int(top + image.shape[1]*np.tan(-angle))\n",
    "    return top, bott"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2255e4b-dbca-4da1-a27d-5ea275165826",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1194/1194 [1:03:59<00:00,  3.22s/it]\n"
     ]
    }
   ],
   "source": [
    "DEBUG = False\n",
    "\n",
    "# set amount to down-sample image when doing convolultions to make process faster\n",
    "scale_factor = 10\n",
    "\n",
    "# Use reference to histogram match images, makes thresholding easier\n",
    "reference = cv2.imread('../WWBEE24_images/Round01/Hive02/2024_06_18/h02b16.JPG')\n",
    "\n",
    "# Get List of Img File Paths\n",
    "img_fps = glob('../WWBEE24_images/Round*/*/*/*')\n",
    "\n",
    "img_fps = sorted(img_fps)\n",
    "#np.random.shuffle(img_fps)\n",
    "\n",
    "for img_fp in tqdm(img_fps):\n",
    "    \n",
    "    if DEBUG:\n",
    "        img_fp = glob('../WWBEE24_images/Round*/*/2024_06_05/h01bee45.JPG')[0]\n",
    "\n",
    "\n",
    "    # extract metadata from filepath\n",
    "    date = img_fp.split('/')[-2]\n",
    "    bee_id = img_fp.split('/')[-1].split('.')[0].replace('_','-')\n",
    "    \n",
    "    new_fp = '../2_live_bees/1_cards/' + date + '_' + bee_id + '.png'\n",
    "    metadata_fp = '../2_live_bees/1_metadata/' + date + '_' + bee_id + '.json'\n",
    "    if os.path.exists(new_fp) and os.path.exists(metadata_fp) and (not DEBUG):\n",
    "        continue\n",
    "    \n",
    "    metadata = {}\n",
    "    img = cv2.imread(img_fp)\n",
    "\n",
    "    matched = match_histograms(img, reference, channel_axis=-1)\n",
    "\n",
    "\n",
    "    \n",
    "    # Scale image so it's faster to process and convert to gray so use intensity values\n",
    "    img_gray = cv2.cvtColor(matched, cv2.COLOR_BGR2GRAY)\n",
    "    scaled_img = img_gray[::scale_factor,::scale_factor] # crude way to scale images - just take every nth pixel\n",
    "    #scaled_img = cv2.blur(scaled_img, (9,9)) # Could also blur, but this is effecively done by the edge detector anyways\n",
    "    \n",
    "    if DEBUG:\n",
    "        plt.figure()\n",
    "        plt.imshow(scaled_img)\n",
    "\n",
    "    # Create a white rectangle kind of the same shape as the white paper background\n",
    "    structured_element = (np.ones((300,120))*150).astype('uint8')\n",
    "\n",
    "    # convolve structured element with scaled image, to find paper in images\n",
    "    convolved = fftconvolve(scaled_img, structured_element, mode='same', axes=None)\n",
    "    points = peak_local_max(convolved, min_distance=50, threshold_abs=10000, num_peaks=24)\n",
    "    if '2024_06_06/h05bee07' in img_fp:\n",
    "        points += [[200,320]]\n",
    "\n",
    "    \n",
    "    if DEBUG:\n",
    "        plt.figure()\n",
    "        plt.imshow(convolved)\n",
    "        # visualize the peaks that we found\n",
    "        for i in range(len(points)):\n",
    "            convolved[points[i][0]-10:points[i][0]+10, points[i][1]-10:points[i][1]+10] = 0\n",
    "        plt.figure()\n",
    "        plt.imshow(convolved)\n",
    "    \n",
    "    # Find the peak closest to the center (usually the white paper) \n",
    "    min_dist = np.inf\n",
    "    img_center = (scaled_img.shape[0]//2, scaled_img.shape[1]//2)\n",
    "    for p in points:\n",
    "        dist_to_center = ((p - img_center)**2).mean()\n",
    "        if dist_to_center < min_dist:\n",
    "            min_dist = dist_to_center\n",
    "            paper_center = p*scale_factor\n",
    "\n",
    "    if '2024_06_05/h01bee45.JPG' in img_fp:\n",
    "        paper_center = [1980, 4410]\n",
    "    \n",
    "    # get a rectangle around the paper center\n",
    "    rx, ry = 1300, 4000\n",
    "    paper_sx, paper_ex = max(paper_center[1]-rx,0), min(paper_center[1]+rx, img.shape[1])\n",
    "\n",
    "    # crop around the paper\n",
    "    crop = img[:, paper_sx:paper_ex]\n",
    "    \n",
    "    if DEBUG:\n",
    "        plt.figure()\n",
    "        plt.imshow((crop < 220).astype('uint8')*255)\n",
    "\n",
    "    scaled_crop = crop[::scale_factor,::scale_factor] \n",
    "    \n",
    "    # Compute the Canny filter\n",
    "    edges = feature.canny(cv2.cvtColor(scaled_crop, cv2.COLOR_BGR2GRAY), sigma=4)\n",
    "    \n",
    "    if DEBUG:\n",
    "        plt.figure()\n",
    "        plt.imshow(edges)\n",
    "    \n",
    "    # Classic straight-line Hough transform\n",
    "    tested_angles = np.linspace(-np.pi / 4, np.pi / 4, 360, endpoint=False)\n",
    "    h, theta, d = hough_line(edges, theta=tested_angles)    \n",
    "    peaks = hough_line_peaks(h, theta, d, num_peaks=2)\n",
    "\n",
    "\n",
    "    if DEBUG:\n",
    "        # Plot detected hough lines\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "        ax = axes.ravel()\n",
    "        \n",
    "        ax[0].imshow(edges)\n",
    "        ax[0].set_title('Input image')\n",
    "        ax[0].set_axis_off()\n",
    "        \n",
    "        ax[1].imshow(edges)\n",
    "        ax[1].set_title('Detected lines')\n",
    "        \n",
    "        for _, angle, dist in zip(*peaks):\n",
    "            (x0, y0) = dist * np.array([np.cos(angle), np.sin(angle)])\n",
    "            ax[1].axline((x0, y0), slope=np.tan(angle + np.pi / 2))\n",
    "    \n",
    "    # hough line gives us the equation for a line as a distance from the origin\n",
    "    # and the angle of a line going through the origin normal to the line of interest\n",
    "    # We need to translate this into pixel locations at the top and bottom edges of the image (x1 and x2)\n",
    "    # for both lines \n",
    "    x1,x2 = get_horizontal_edge_intersection_points(edges, (peaks[1][0], peaks[2][0]))\n",
    "    # if can only find one line, use proximity to the paper center to decide if it is \n",
    "    # the left or right edge of the paper and just guess size of the paper\n",
    "    if len(peaks[1]) == 1:\n",
    "        if x1 > (paper_center[1] - paper_sx) // scale_factor:\n",
    "            x3, x4 = x1 - 160, x2 - 160\n",
    "        else:\n",
    "            x3, x4 = x1 + 160, x2 + 160\n",
    "    else:\n",
    "        x3,x4 = get_horizontal_edge_intersection_points(edges, (peaks[1][1], peaks[2][1]))\n",
    "\n",
    "    # find the minimum and maximum location of the paper in the image\n",
    "    min_x = max(min([x1,x2,x3,x4]),0)\n",
    "    max_x = min(max([x1,x2,x3,x4]),scaled_crop.shape[1])\n",
    "\n",
    "    # get the rotation angle from one of the hough lines\n",
    "    rotation_angle = peaks[1][0]\n",
    "\n",
    "    # rotate the histogram matched image that amount\n",
    "    rotated = ndimage.rotate(matched, rotation_angle*180/np.pi, mode='constant', cval=255)\n",
    "\n",
    "    # calculate the location of min_x and max_y in the new rotated space\n",
    "    rotation_x_shift = np.abs(img.shape[0]*np.sin(-rotation_angle)     )\n",
    "    x_start = int(rotation_x_shift + np.cos(rotation_angle)*(paper_sx + min_x*scale_factor))\n",
    "    x_end = int(rotation_x_shift + paper_sx*np.cos(-rotation_angle) + np.cos(-rotation_angle)*min(sorted([x1,x2,x3,x4])[-2],scaled_crop.shape[1])*scale_factor)\n",
    "\n",
    "\n",
    "    # sometimes when we used just one peak, there is still a border around the paper, we can find and crop that using \n",
    "    # the intensities of the columns\n",
    "    \n",
    "    \n",
    "    rotated_crop = rotated[:,x_start:x_end]\n",
    "    if DEBUG:\n",
    "        plt.figure()\n",
    "        plt.imshow(rotated)\n",
    "        plt.title('rotated')\n",
    "        plt.figure()\n",
    "        plt.imshow(rotated_crop)\n",
    "\n",
    "\n",
    "    x_end_hist = rotated_crop.shape[1] - 1\n",
    "    x_start_hist = 1\n",
    "\n",
    "    pixels_below_thres = np.where(rotated_crop.mean(axis=2).mean(axis=0) < 150)[0]\n",
    "    i = 0\n",
    "    while np.in1d(x_start_hist, pixels_below_thres):\n",
    "        x_start_hist += 1\n",
    "        i += 1\n",
    "        if i >= 100:\n",
    "            break\n",
    "    i = 0\n",
    "    while np.in1d(x_end_hist, pixels_below_thres):\n",
    "        x_end_hist -= 1\n",
    "        i += 1\n",
    "        if i >= 100:\n",
    "            break\n",
    "\n",
    "    \n",
    "    if DEBUG:\n",
    "        plt.imshow(rotated_crop)\n",
    "        plt.figure()\n",
    "        plt.hist(rotated_crop.mean(axis=2).mean(axis=0), bins=100)\n",
    "        plt.figure()\n",
    "        plt.plot(rotated_crop.mean(axis=2).mean(axis=0))\n",
    "        plt.figure()\n",
    "        plt.imshow(rotated_crop[:,x_start_hist:x_end_hist])\n",
    "    rotated_crop = rotated[:,x_start + x_start_hist:x_start + x_end_hist]\n",
    "    \n",
    "    rotated = ndimage.rotate(img, rotation_angle*180/np.pi, mode='constant', cval=255)\n",
    "\n",
    "    # Save cropped image\n",
    "    cv2.imwrite(new_fp, rotated[:,x_start + x_start_hist:x_start + x_end_hist])\n",
    "\n",
    "    # Save metadata\n",
    "    metadata['card_angle'] = rotation_angle*180/np.pi\n",
    "    metadata['card_rotated_x_start'] = x_start + x_start_hist\n",
    "    metadata['card_rotated_x_end'] = x_start + x_end_hist\n",
    "    with open(metadata_fp, \"w\") as outfile: \n",
    "        json.dump(metadata, outfile)\n",
    "    if DEBUG:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3637d8e-c860-4c0f-9903-6f58bad20708",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbb45f9-9d0a-4995-9f26-0efc4b5f74ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
