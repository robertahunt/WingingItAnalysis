{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18805d0e-c161-4608-a849-0a2e45d4b86a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nThis notebook is used to do an initial pass at the wing segmentation in the card images.\\nIt does this by:\\n 1. Matching the image histogram to a reference image to help with thresholding\\n 2. Blurring the image\\n 3. Thresholding the image\\n 4. Finding the large contour that is closest to the center of the image (we assume this is the wing)\\n 5. Using a smaller blur and thresholding the contour to that (so we get the find edges more precisely)\\n 6. Saving the mask and segmentations\\n\\nOnce this notebook was done running, it was necessary to go through the images, check if the segmentation worked, and \\nmanually correct many of the segmentations. These manual corrections are saved in '2_card_mask_manual_corrections'\\nand combined with the masks from this notebook into the folder '2_final_masks'\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This notebook is used to do an initial pass at the wing segmentation in the card images.\n",
    "It does this by:\n",
    " 1. Matching the image histogram to a reference image to help with thresholding\n",
    " 2. Blurring the image\n",
    " 3. Thresholding the image\n",
    " 4. Finding the large contour that is closest to the center of the image (we assume this is the wing)\n",
    " 5. Using a smaller blur and thresholding the contour to that (so we get the find edges more precisely)\n",
    " 6. Saving the mask and segmentations\n",
    "\n",
    "Once this notebook was done running, it was necessary to go through the images, check if the segmentation worked, and \n",
    "manually correct many of the segmentations. These manual corrections are saved in '2_card_mask_manual_corrections'\n",
    "and combined with the masks from this notebook into the folder '2_final_masks'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1266e135-8b16-4065-8e77-79f9b2a2181b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "\n",
    "from scipy import ndimage\n",
    "from skimage.measure import label\n",
    "\n",
    "from numpy import linalg\n",
    "from scipy.sparse.linalg import eigs\n",
    "\n",
    "from skimage.exposure import match_histograms\n",
    "\n",
    "from utils import is_wing_facing_up, segment_contour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4dbc7e-d192-4112-a816-7e5124369ce3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6789dd4d-1338-4155-89a8-233bda8baec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for fp in glob('../2_live_bees/2_card_segs/*'):\n",
    "#    os.remove(fp)\n",
    "#for fp in glob('../2_live_bees/2_card_masks/*'):\n",
    "#    os.remove(fp)\n",
    "#for fp in glob('../2_live_bees/2_card_segs_and_orig/*'):\n",
    "#    os.remove(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e289d562-8f97-405d-8a43-d3ee78687dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1193/1193 [00:46<00:00, 25.79it/s]\n"
     ]
    }
   ],
   "source": [
    "DEBUG = False\n",
    "\n",
    "scale_factor = 2\n",
    "blur_kernel_size = 11\n",
    "img_fps = sorted(glob('../2_live_bees/1_cards/*'))\n",
    "np.random.shuffle(img_fps)\n",
    "reference = cv2.imread('../2_live_bees/reference_card_2024_06_13_h05b78.png')\n",
    "reference = cv2.imread('../2_live_bees/reference_card_2024_06_06_h05bee62.png')\n",
    "subset = []\n",
    "\n",
    "\n",
    "for img_fp in tqdm(img_fps):\n",
    "    if DEBUG:\n",
    "        img_fp = '../2_live_bees/1_cards/2024_07_24_h34b11.png'#img_fps[5]\n",
    "        #img_fp = img_fps[0]\n",
    "\n",
    "    fn = img_fp.split('/')[-1]\n",
    "    if len(subset):\n",
    "        if fn not in subset:\n",
    "            continue\n",
    "    date = '_'.join(fn.split('_')[:-1])\n",
    "    bee_id = fn.split('_')[-1].split('.')[0]\n",
    "\n",
    "\n",
    "    threshold = 160\n",
    "\n",
    "    \n",
    "    img = cv2.imread(img_fp)\n",
    "\n",
    "    matched = match_histograms(img, reference, channel_axis=-1)\n",
    "    \n",
    "    if DEBUG:\n",
    "        plt.figure()\n",
    "        plt.imshow(img)\n",
    "        plt.title('img')\n",
    "    if DEBUG:\n",
    "        plt.figure()\n",
    "        plt.imshow(matched)\n",
    "        plt.title('histogram matched')\n",
    "    \n",
    "    crop_top = 300//scale_factor\n",
    "    crop_bott = 300//scale_factor\n",
    "    crop_right = 50//scale_factor\n",
    "    crop_left = 50//scale_factor\n",
    "\n",
    "    scaled_img = matched[::scale_factor,::scale_factor] # crude downsampling\n",
    "    scaled_img = scaled_img[crop_top:scaled_img.shape[0] - crop_bott, crop_left:scaled_img.shape[1]-crop_right]\n",
    "\n",
    "    if DEBUG:\n",
    "        plt.figure()\n",
    "        plt.imshow(scaled_img)\n",
    "        plt.title('downscaled')\n",
    "    y_start_hist = 1\n",
    "    y_end_hist = scaled_img.shape[0] - 1\n",
    "\n",
    "    pixels_below_thres = np.where(scaled_img.mean(axis=2).mean(axis=1) < 170)[0]\n",
    "    \n",
    "    while np.in1d(y_start_hist, pixels_below_thres):\n",
    "        y_start_hist += 1\n",
    "    while np.in1d(y_end_hist, pixels_below_thres):\n",
    "        y_end_hist -= 1\n",
    "        \n",
    "    crop_top += y_start_hist\n",
    "    crop_bott += scaled_img.shape[0] - y_end_hist\n",
    "    scaled_img = scaled_img[y_start_hist:y_end_hist]\n",
    "    \n",
    "    blurred = cv2.blur(scaled_img, (blur_kernel_size, blur_kernel_size))\n",
    "\n",
    "    if DEBUG:\n",
    "        plt.figure()\n",
    "        plt.imshow(blurred)\n",
    "        plt.title('blurred')\n",
    "    blurred_gray = blurred[:,:,0]#cv2.cvtColor(blurred, cv2.COLOR_BGR2GRAY)\n",
    "    if '2024_06_06_h05bee50' in img_fp:\n",
    "        blurred_gray[:,:10] = 255\n",
    "    thres = blurred_gray < threshold\n",
    "\n",
    "    if DEBUG:\n",
    "        plt.figure()\n",
    "        plt.imshow(thres)\n",
    "        plt.title('thresholded')\n",
    "\n",
    "\n",
    "    closed = ndimage.binary_closing(thres, iterations=3).astype('uint8')*255\n",
    "    \n",
    "    contours,hierarchy = cv2.findContours(closed, 1, 2)\n",
    "    four_biggest_blobs = []\n",
    "    i=0\n",
    "    \n",
    "    # encountered an error that it would detect dark edges sometimes instead, so just find a blob\n",
    "    # with a reasonable aspect ratio\n",
    "    area_sorted_indices = np.argsort([cv2.contourArea(x) for x in contours])\n",
    "    while (len(four_biggest_blobs) < 4) and (i<10):\n",
    "        if i >= len(area_sorted_indices):\n",
    "            break\n",
    "        blob_index = area_sorted_indices[-i]\n",
    "        i+=1\n",
    "        x,y,w,h = cv2.boundingRect(contours[blob_index])\n",
    "        blob_area = cv2.contourArea(contours[blob_index])\n",
    "    \n",
    "        if w/h > 5 or h/w > 5:\n",
    "            pass\n",
    "        elif blob_area < 10000:\n",
    "            pass\n",
    "        else:\n",
    "            four_biggest_blobs += [blob_index]\n",
    "\n",
    "\n",
    "    # find blob closest to center\n",
    "    min_dist = np.inf\n",
    "    img_center = (thres.shape[0]//2, thres.shape[1]//2)\n",
    "    closest_blob = np.nan\n",
    "    for blob_idx in four_biggest_blobs:\n",
    "        blob = contours[blob_idx]\n",
    "        seg, mask = segment_contour(scaled_img, blob)\n",
    "    \n",
    "        \n",
    "        mask_center = np.array(np.where(mask[:,:,0] > 0.5)).mean(axis=1)\n",
    "        dist_to_center = ((mask_center - img_center)**2).mean()\n",
    "        if dist_to_center < min_dist:\n",
    "            min_dist = dist_to_center\n",
    "            wing_center = mask_center*scale_factor\n",
    "            closest_blob_mask = mask[:,:,0]\n",
    "            closest_blob_seg = seg\n",
    "\n",
    "    # decide if the wing is upside down based on vein locations\n",
    "    mask_center = np.array(np.where(closest_blob_mask > 0.5)).mean(axis=1)\n",
    "    veins = (closest_blob_seg[:,:,0] < 50).astype('uint8')*255\n",
    "    if DEBUG:\n",
    "        plt.figure()\n",
    "        plt.imshow(veins)\n",
    "        plt.title('veins')\n",
    "    veins_center = np.array(np.where(veins > 0.5)).mean(axis=1)\n",
    "    \n",
    "    if mask_center[0] < veins_center[0]:\n",
    "        flip = True\n",
    "    else:\n",
    "        flip = False\n",
    "\n",
    "\n",
    "    closest_blob_mask = np.pad(closest_blob_mask,((crop_top, crop_bott),(crop_left, crop_right)))\n",
    "    if flip:\n",
    "        closest_blob_mask = np.flipud(closest_blob_mask)\n",
    "        closest_blob_seg = np.flipud(closest_blob_seg)\n",
    "        scaled_img = np.flipud(scaled_img)\n",
    "\n",
    "\n",
    "\n",
    "    if DEBUG:\n",
    "        plt.figure()\n",
    "        plt.imshow(closest_blob_mask)\n",
    "        plt.title('wing detected')\n",
    "    \n",
    "    original_mask = cv2.resize(closest_blob_mask, (img.shape[1],img.shape[0]))\n",
    "    original_mask = (original_mask > 0.5).astype('uint8')\n",
    "    if flip:\n",
    "        original_mask = np.flipud(original_mask)\n",
    "    \n",
    "    if DEBUG:\n",
    "        plt.figure()\n",
    "        plt.imshow(original_mask)\n",
    "        plt.title('mask in original orientation')\n",
    "    \n",
    "    seg = np.ones(img.shape)*255\n",
    "    seg[np.where(original_mask > 0)] = img[np.where(original_mask>0)]\n",
    "\n",
    "    # now we tighten the borders on the contour a bit\n",
    "    a = cv2.cvtColor(seg.astype('uint8'), cv2.COLOR_BGR2GRAY)\n",
    "    a = cv2.blur(a, (3,3))\n",
    "    thres2 = (a < 220).astype('uint8')*255\n",
    "\n",
    "    \n",
    "    if DEBUG:\n",
    "        plt.figure()\n",
    "        plt.imshow(thres2)\n",
    "        plt.title('Tightened Threshold')\n",
    "    \n",
    "    contours,hierarchy = cv2.findContours(thres2, 1, 2)\n",
    "    area_sorted_indices = np.argsort([cv2.contourArea(x) for x in contours])\n",
    "    biggest_contour_index = area_sorted_indices[-1]\n",
    "    biggest_contour = contours[biggest_contour_index]\n",
    "    seg2 = np.zeros(seg.shape[:2]).astype('uint8')\n",
    "    seg2,mask2 = segment_contour(img, biggest_contour)\n",
    "\n",
    "    if DEBUG:\n",
    "        plt.figure(figsize=(20,20))\n",
    "        plt.imshow(seg2)\n",
    "    \n",
    "    \n",
    "    seg_and_orig = np.ones((img.shape[0], img.shape[1]*2, img.shape[2]))*255\n",
    "    seg_and_orig[np.where(mask2 > 0)] = img[np.where(mask2>0)]\n",
    "    seg_and_orig[:,img.shape[1]:] = img\n",
    "\n",
    "    mask_fp = f'../2_live_bees/2_card_masks/{date}_{bee_id}.png'\n",
    "    seg_fp = f'../2_live_bees/2_card_segs/{date}_{bee_id}.png'\n",
    "    seg_and_orig_fp = f'../2_live_bees/2_card_segs_and_orig/{date}_{bee_id}.png'\n",
    "    \n",
    "    cv2.imwrite(mask_fp, mask2*255)\n",
    "    cv2.imwrite(seg_fp, seg2)\n",
    "    cv2.imwrite(seg_and_orig_fp, seg_and_orig)\n",
    "    \n",
    "\n",
    "    if DEBUG:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a43aa4a-caa6-4399-b067-8e185dbf90fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "for fn in seen:\n",
    "    if fn not in problem_wings:\n",
    "        old_fp = f'../2_live_bees/2_card_masks/{fn}'\n",
    "        new_fn = fn.replace('_L.png','.png').replace('_R.png','.png')\n",
    "        new_fp = f'../2_live_bees/2_card_masks_corrected/{new_fn}'\n",
    "        #shutil.copyfile(old_fp, new_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6038c2e0-68c6-425c-9c1e-298e623aa4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "for fn in seen:\n",
    "    old_fp = f'../2_live_bees/2_card_masks/{fn}'\n",
    "    new_fn = fn.replace('_L.png','.png').replace('_R.png','.png')\n",
    "    new_fp = f'../2_live_bees/2_card_masks/{new_fn}'\n",
    "    if os.path.exists(old_fp):\n",
    "        pass#shutil.move(old_fp, new_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "605a96b2-f0a6-4689-8d25-6c4102bf4653",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1193/1193 [00:00<00:00, 3264.09it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create final masks folder based on manual annotation if available, or mask if not\n",
    "\n",
    "img_fps = sorted(glob('../2_live_bees/1_cards/*'))\n",
    "\n",
    "\n",
    "for img_fp in tqdm(img_fps):\n",
    "    img_fp = Path(img_fp)\n",
    "    fn = img_fp.name\n",
    "    \n",
    "    mask_fp = '../2_live_bees/2_card_masks/' + fn\n",
    "    manual_mask_fp = '../2_live_bees/2_card_mask_manual_corrections/' + fn\n",
    "    final_fp = '../2_live_bees/2_final_masks/' + fn\n",
    "\n",
    "    if os.path.exists(manual_mask_fp):\n",
    "        shutil.copyfile(manual_mask_fp, final_fp)\n",
    "    else:\n",
    "        shutil.copyfile(mask_fp, final_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfa5a8dc-819a-4e22-8ce9-b4efda851a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1193/1193 [14:50<00:00,  1.34it/s]\n"
     ]
    }
   ],
   "source": [
    "# Remake segmentations including final masks\n",
    "\n",
    "img_fps = sorted(glob('../2_live_bees/1_cards/*'))\n",
    "\n",
    "\n",
    "for img_fp in tqdm(img_fps):\n",
    "    img_fp = Path(img_fp)\n",
    "    fn = img_fp.name\n",
    "    \n",
    "    mask_fp = '../2_live_bees/2_final_masks/' + fn\n",
    "    seg_fp = '../2_live_bees/2_card_segs/' + fn\n",
    "    seg_and_orig_fp = '../2_live_bees/2_card_segs_and_orig/' + fn\n",
    "\n",
    "    img = cv2.imread(img_fp)\n",
    "    mask = cv2.imread(mask_fp, cv2.IMREAD_GRAYSCALE)\n",
    "    seg = np.ones(img.shape).astype('uint8')*255\n",
    "    seg[np.where(mask > 0.5)] = img[np.where(mask > 0.5)]\n",
    "    \n",
    "    seg_and_orig = np.ones((img.shape[0], img.shape[1]*2, img.shape[2]))*255\n",
    "    seg_and_orig[np.where(mask > 0)] = img[np.where(mask>0)]\n",
    "    seg_and_orig[:,img.shape[1]:] = img\n",
    "\n",
    "    \n",
    "    cv2.imwrite(seg_and_orig_fp, seg_and_orig)\n",
    "    cv2.imwrite(seg_fp, seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088a6915-5874-4606-9f66-fcf56db727bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
